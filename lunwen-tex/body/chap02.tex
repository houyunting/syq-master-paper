% !TEX TS-program = XeLaTeX
% !TEX encoding = UTF-8 Unicode

\chapter{独立分量分析}
\label{chap02}
\section{盲源分离\ucite{AAPO01}}

\subsection{盲源分离问题的提出}
    让我们来考虑这样的一般情况：有这么一组信号，是由几个物理
对象或物理源发出的，物理源可以是发出电信号的不同脑区，可以是
同一房间讲话的人，也可能是发射无线电波的移动电话。进一步假设
存在多个传感器或接收机，而这些传感器安置在不同的位置，从而，
每个传感器可以分别以略为不同的权重记录各物理源信号的某种混合。
    为使问题的陈述更为简单，我们假定有三个信号源，同时有三个
观测信号。把观测信号记为$x_1(t), x_2(t) \,\mbox{和}\, x_3(t)$，
它们是所记录的信号在$t$时间点处的幅值；
原始信号记为$s_1(t), s_2(t)\,和\,s_3(t)$。
这样$x_i(t)$是$s_i(t)$的加权和，而加权系数依赖于源和传感器之间的距离：

\parbox{10cm}{
\begin{eqnarray*}
x_1(t)=a_{11}s_1(t)+a_{12}s_2{t}+a_{13}s_3(t) \\
x_2(t)=a_{21}s_1(t)+a_{22}s_2{t}+a_{23}s_3(t) \\
x_3(t)=a_{31}s_1(t)+a_{32}s_2{t}+a_{33}s_3(t) \\
\end{eqnarray*}
}\hfill
\parbox{3cm}{\begin{eqnarray} \label{bss_compose}\end{eqnarray}}

式中，$a_{ij}$是常值系数，表示混合的权重。$a_{ij}$是未知的，
因为我们不可能了解物理混合系统的全部特性(这通常是极其困难的)，
所以我们无法知道$a_{ij}$的值。源信号$s_i$也同样是未知的，
而这正是要解决的问题：因为我们不能对它们进行直接记录。
    
我们想要做的就是利用$x_1(t)$, $x_2(t)$和$x_3(t)$这些混合量找出原始信号
这就是盲源分离(BSS)问题。盲意味着我们对原始信号所知甚少。
    不妨假设混合系数$a_{ij}$具有足够的差异，使得他们构成的矩阵可逆。
因此构成的矩阵可逆。因此存在一个以元素$w_{ij}$为系数的矩阵$W$，使得我们
可以用它分离出源信号$s_i$：
 
\parbox{10cm}{
\begin{eqnarray*}
s_1(t)=w_{11}x_1(t)+w_{12}x_2{t}+w_{13}x_3(t) \\
s_2(t)=w_{21}x_1(t)+w_{22}x_2{t}+w_{23}x_3(t) \\
s_3(t)=w_{31}x_1(t)+w_{32}x_2{t}+w_{33}x_3(t) \\
\end{eqnarray*}
}\hfill
\parbox{3cm}{\begin{eqnarray}\label{bss_slover} \end{eqnarray}}

如果我们已经知道公式(\ref{bss_compose})中的那些系数$a_{ij}$，将它们形成的矩阵求逆
即可得到矩阵$W$。
    
\subsection{基于独立性的源分离\ucite{AAPO01}}
现在的问题是：如何估计公式(\ref{bss_slover})中的系数$w_{ij}$？
我们希望获得一种普适性的方法，使它能适合许多不同的场合，
并给最开始提出的问题——即为多元数据寻找一个好的表示法，提供一种答案。
但是我们只能使用非常一般的统计性质，因为$x_1, x_2, x_3$是我们的全部观测。
我们还希望找到一个矩阵$W$，使得这个好的表示法可以用源信号
$s1$, $s2$, $s3$给出。
    
仅仅通过考虑信号的统计独立性，就可以找到上述问题的一个令人惊奇
简单求解方式。事实上如果信号是非高斯的，那么只需确定系数$w_{ij}$，
使得信号：
\parbox{10cm}{
\begin{eqnarray*}
y_1(t)=w_{11}x_1(t)+w_{12}x_2{t}+w_{13}x_3(t) \\
y_2(t)=w_{21}x_1(t)+w_{22}x_2{t}+w_{23}x_3(t) \\
y_3(t)=w_{31}x_1(t)+w_{32}x_2{t}+w_{33}x_3(t) \\
\end{eqnarray*}
}\hfill
\parbox{3cm}{\begin{eqnarray}\label{bss_slover} \end{eqnarray}}

是统计独立的即可。如果信号$y_1$，$y_2$和$y_3$是统计独立的，
那么它们就等同于原始信号$s_1$, $s_2$和$s_3$
(他们可能是某种标量常数乘积的关系
也就是说一个信号可能是另一个信号乘以一个标量的比例常数，
但这并不重要)。
    事实上，仅仅利用统计独立性的信息，我们就可以估计出图(****)
中信号所对应的系数矩阵W，从而得到如图(*****)所示的源信号
(这些信号是用后文提到的FastICA算法估算出来的)。可以看到，
从一个貌似噪声的数据集中，利用一个只用到统计独立性信息的算法
就能将源信号估计出来。而估计得到的信号确实等于我们用于产生
图(****)中混合信号的源信号(源信号没有给出，不过它们确实与算法
找出的信号在本质上是等价的)。而在源分离的问题中，原始信号就是
数据集的“独立成分”。


\section{独立成分分析\ucite{AAPO01}}
\subsection{定义}
前面我们已经看到，盲源分离问题可以归结为寻找一个线性表示，使得
该表示对应的成分统计独立。在实际情形下，我们一般不可能找到一个其成
真正独立的表示，但是至少能够找到一个其成分尽可能独立的表示。

这使我们能够对ICA进行这样简单的定义：

给定随机变量的一组观测$(x_1(t)，x_2(t)，...,x_n(t))$，其中t是时间或者
样本标号，假设它们由独立成分线性混合：
\begin{equation} \label{matrix_reslover}
\left[ \begin{array}{c} 
x_1(t) \\
x_2(t) \\
. \\
. \\
. \\
x_n(t)
\end{array} \right]
=\bm{A}
\left[ \begin{array}{c} 
s_1(t) \\
s_2(t) \\
. \\
. \\
. \\
s_n(t)
\end{array} \right]
\end{equation}
式中，A是某个未知矩阵。我们仅能观察到$x_i(t)$的情况下，独立成分分析就要
同时估计出矩阵$\bm{A}$和$s_i(t)$。
注意此处我们还鉴定独立成分$s_i(t)$的数目与观测变量的数目相同；
其实这只是一个简化假设，而不是必须的。

可以表明，该问题是适定的，
也就是说公式(\ref{matrix_reslover})中的模型可估，而且仅当各成分$s_i$是
非高斯性的，这是一个具体要求。关于对于为什么要求非高斯性的讨论，
可以参考(*****)。
    
关于ICA更加严格的定义，请参考(****)和(****)

\subsection{如何寻找独立成分}
在除独立性外没有其他任何假设的情况下，仍能从线性混合中估计出独立
成分，这个结论可能让人觉得非常吃惊。那么下面我们试图简要地回答上述情况
为什么是可能的，以及如何实现两个基本疑问。
\paragraph*{仅仅不相关是不够的***}：首先需要注意的是，
独立性是比不相关性强得多的性质。对于盲源分离问题，我们实际上可以找到信号的许多不同的不相关表示法，但这些表示未必独立，也未必能将源信号分离出来。
不相关性就其本身而言是不足以分离这些成分的。
这也是主成分分析或因子分析不能分离信号的原因：
它们给出的成分除了不相关外就没有更多信息了。
    
事实上，利用我们熟知的去相关方法，可以将独立成分的任何线性混合变换
成不相关成分，其中的混合变换是正交的(参考****)。这样，ICA的要点就是估计
去相关之后留下的未知正交矩阵。这是经典方法所不能估计的，因为它们和去相关
方法一样，是基于协方差信息的。
    
\paragraph*{非线性去相关是基本ICA方法}：
表达独立性如何强于不相关行的一种说法是，
独立性本事就蕴含了\textbf{非线性不相关性}：
若$s_1$和$s_2$独立，那么任何非线性变化$g(s_1)$和$h(s_2)$
都是不相关的(在它们之间协方差为零的意义下)。
与此形成鲜明对比的是，对于两个仅仅不相关的随机变量，
这样两个非线性变换一般不再具有零协方差。
这样我们可以通过一种更强形式的去相关运算来实现ICA：
即，寻找一个表示，使得$y_i$即使通过非线性变化仍然不相关。
这给出了估计矩阵$W$的一个简单原理：

\textbf{ICA估计原理1}：非线性去相关。寻找矩阵$\bm{W}$，
使的对任何$i \ne j$，成分$y_i$和$y_j$不相关，
而且变换之后的成分$g(y_i)$和$h(y_j)$也不相关，其中，
$g$和$h$是某些适当的非线性函数。

	这是估计ICA的一个有效的方法：如果非线性函数选得适当，此方法的确能找到
独立成分。虽然这个原理非常直观，但她却遗留了一个重要的问题：非线性函数
$g$和$h$如何选择？该问题的答案可以从估计理论和信息论中找到。
估计理论提供了可以估计任何一个统计模型的最为经典的方法：
极大似然估计(参见***)。
信息论可以给出独立性的一些准确度量，如互信息(参见***)。
利用其中任何一种理论，我们都能确定出满意的非线性函数$g$和$h$。
    
\paragraph*{独立成分是极大非高斯性成分}：
ICA估计另一个非常直观和重要的原则是极大非高斯性(参加***)。
其思路是，根据中心极限定义，非高斯性随机变量之和比原变量更加接近高斯变量。因此，如果我们取观测混合变量的一个线性组合$y=\sum b_i x_i$
(因为混合模型是线性的，因此该线性组合同时也是独立成分的一种线性组合)，
如果它等于独立成分之一，那么它的非高斯性达到极大。
这是因为，如果它确实是两个或更多成分的混合，按中心极限定义，
该混合将更接近高斯分布。
    这样，相关的原理可以表述为：

	\textbf{ICA估计原理2}：极大高斯性。在y的方差为常数的约束下，球现行组合
	y=sigma-i(bi*xi)非高斯性的局部极大值。每个局部极大值给出一个独立成分。
    
	为了在实际应用中度量非高斯性，我们可以使用一些变量，
比方说\textbf{峭度}。峭度是一个高阶累积量，
它是方差的某种推广(利用高阶多项式)。累积量具有一些有趣的代数和统计性质，
这也是它们在ICA理论中起着重要作用的原因。
    
有意思的一点是，极大非高斯性原理表明了ICA和独立发展技术，
称为\textbf{投影寻踪}的这项技术之间的紧密关系。
在投影寻踪方法里，我们实际上也是寻找具有极大非高斯性的线性组合，
并用于可视化或其它目的。这样独立成分可以解释成投影寻寻踪的方向。
    
当ICA用于提取特征时，极大非高斯性原理也表明了它与在特征提取的神经科学
理论中使用过的\textbf{稀疏编码}之间的紧密关系(参看***)。
稀疏编码的思路是将数据用成分表示，使得只有很少数量的成分是同时激活的。
在某些情形下，这等价于寻找极大非高斯性成分。

ICA与投影寻中和稀疏编码之间的这些联系，都和一个更为深入的结果有关，
该结果表明，ICA给出了一个\textbf{尽可能结构化}的线性表示。
此论断可以用信息论概念给出其严格的意义(参见***)，
并且相关结果还表明，独立成分在许多方面比原始随机变量更容易处理。
特别地，独立成分比原始变量更加容易编码(压缩)。
    
\textbf{ICA估计所需信息比协方差更多}：还有很多其它方法也可以估计ICA模型。
这些方法的共同点是，它们考虑了没有包含在协方差矩阵中的某些统计量。
(协方差矩阵包含的是所有xi对之间的协方差)。

利用协方差矩阵，我们可以在通常线性意义下取出各成分间的相关性，
但仅此而已。故所有ICA方法都用到了某种形式的\textbf{高阶统计量}，高阶特别地
意味着这些信息并未包含在协方差矩阵中。到此为止我们已经遇到过了两类
高阶信息：非线性相关性和峭度。也可以使用其它很多类型的高阶统计量。
    
\textbf{数值方法是重要的}：除了估计原理外，我们还必须找到一个具体算法，
以实现所需的计算。由于估计原理使用的是非二次的函数，所需要的计算通常
不能用简单的线性代数来表达，因此算法方面的要求可能是很高的。这样，
数值算法就成为ICA估计方法一个不可缺少的组成部分。

数值方法通常是基于某种目标函数的优化。基本的优化方法是梯度法，
而特别有意思的是一个称为FastICA的不动点算法，它似乎是特别为ICA问题
量身定制的，可以充分地挖掘问题的特殊结构。我们可以采用两种方法任意
一个找到用峭度绝对值度量的非高斯性极大解。
    
\subsection{ICA的约束}
为了确保上面给出的基本ICA模型能被估计，我们必须作出一定的假设和约束。

\textbf{1) 独立成分被假定是统计独立的}
该假设是ICA能够成立的前提，但令人惊讶的是，为保证模型能够被估计，
仅仅这个约束已经基本足够了，这就是ICA能在许多不同领域的应用中，
成为一个强有力的方法的原因。

如果从基本概念上理解，我们说，随机变量$y_1,...,y_n$是独立的，
是指在$i \ne j$时，
有关$y_i$的取值情况对于yj如何取值没有提供任何信息。
从技术角度，独立可以通过概率密度来定义。
定义$p(y_1,y_2,...,y_n)$为$y_i$的联合概率密度函数，$p_i(y_i)$为$y_i$的
边缘概率密度函数(即只考虑$y_i$本身的概率密度函数)。
那么我们说$y_i$是独立的，
当且仅当联合概率密度函数可以因式分解为下面的形式：
\begin{equation}
p(y_1, y_2, ..., y_3) = p_1(y_1)p_2(y_2)...p_n (y_n)
\end{equation}

\textbf{2) 独立成分必须具有非高斯的分布}
我们通常直观地说高斯分布“太简单”了。高斯分布所有高阶累积量都为零，
但是这样的高阶信息对于估计ICA模型来说却是必须的。因此，如果观测变量具有
高斯分布，那么ICA在本质上是不可能实现的。值得注意的是，在基本模型中，我们
没有假定已知那些独立成分的的非高斯分布的样子，否则问题就会相当简单。

\textbf{3) 为简单起见，我们假定未知的混合矩阵是方阵}
换句话说，就是独立成分的个数与观测到的混合量的个数是相同的。对于进一步的
讨论来说，这个假设在某些情况下是不严谨的。但这里做该假设可以大大简化估计
过程，另外得到矩阵$\bm{A}$的估计后，可以计算它的逆(用$\bm{B}$表示)，
并简单地通过下式得到其独立成分：
\begin{equation}
\bm{s}=\bm{B}\bm{x}
\end{equation}
这里同时也假定了混合矩阵是可逆的。如果不是i这样，
就说明存在可以忽略的冗余混合量，这样矩阵就不会是方阵，
也就说说混合量的个数与独立成分的个数是不相等的。

在上面三个假设(或至少第1和第2两个假设)的前提下，ICA模型是可辨识的，
意指混合矩阵与那些独立成分可以被估计至存在一些平凡不确定性(trivial indetterminacies)的程度。对于ICA模型的可辨识性的证明，请参考(***)。
同时(****)中也为可辨识性给出了一种不甚严格但可以帮助理解的构造性证明。
      
\subsection{ICA中的含混因素}
根据以上所定义的ICA模型，很容易发现存在下面一些必然的含混因素或者说，
不确定性。
\paragraph*{1) 无法确定独立成分的方差(能量)}
原因是，$\bm{s}$和$\bm{A}$都是未知的，对于某一个源的任意标量乘积
都能通过对$\bm{A}$矩阵对应的列$a_i$除以对应的标量值$a_i$而抵消：
\begin{equation}
\bm{x}=\sum_{i} (\frac{1}{{\alpha}_i} \bm{\alpha}_i)(s_i {\alpha}_1)
\end{equation}
作为推论，我们也可以用同样的方式对独立成分的幅值进行修正。因为上述分类都是随机变量，
进行修正最自然的方式就是假定它们都具有单位方差：$E\{s_i^2\}=1$。
然而在ICA求解方法，可以通过调整矩阵A来实现该归一化约束。
不过即使这样，仍然遗留了符号的不确定性问题：
我们可以通过对某一独立成分乘以-1而不影响模型。
不过幸运的是这种汗混因素在绝大多数的应用中是无关紧要的。

\paragraph*{2) 无法确定独立成分的次序}
这仍然是$\bm{s}$和$\bm{A}$均为未知造成的，我们可以任意交换求和式中各项的次序，也可以把任意一个独立成分作为第一个。从形式上来说，
就是可以用一个置换矩阵机器逆代入模型，
得到$\bm{x=AP^{-1}Ps}$。
$\bm{Ps}$矩阵的元素萦绕是原来的独立变量$\bm{s_j}$，
但是次序发生了变化。
而矩阵$\bm{AP^{-1}}$则是另一个新的需要通过ICA算法求解的混合矩阵。
 
\subsection{中心化}
不失一般性，我们可以假定所有的混合变量与独立成分具有零均值。
这样可以相当程度地简化理论和算法，并作为一个默认的假设。

实际情况中，往往不满足零均值假设，我们可以进行一些预处理使其满足该要求，
这可以通过对可观测变量进行中心化(centering)实现。就是说在实施ICA之前，
对原始的混合信号$\bm{x'}$
进行预处理：
\begin{equation} 
\bm{x=x'}-E\{\bm{x'}\}
\end{equation}
这样独立成分也同时变为零均值的量，因为：
\begin{equation}
E\{\bm{s}\}=\bm{A}^{-1}E\{\bm{x}\}
\end{equation}
不过通过这样的中心和预处理，混合矩阵仍可保持不变，
因此我们可以放心作为而不用担心影响对混合矩阵的估计。
在完成通过零均值数据对混合矩阵与独立成分的估计工作之后，
%被减掉的均值可以通过简单地在独立成分上加A^(-1)E{x'}而恢复。
    
\subsection{白化}
给定一些随机变量，通过线性变换将它们转变为相互无关的变量是非常直接的事情。
因此试图采用这样的手段去估计独立变量是一个诱人的想法，这类方法一般称为
(whitenig)或者球面化(sphering)，且经常通过主成分分析(principal component analysis)来实现。在本节中，我们指出这是不可能的，
并讨论了ICA和去相关方法的关系。我们将会看到，
白化事实上可作为ICA中一个有用的预处理技术。

不相关是独立性的一个弱化的形式。
比不相关略强的特性是\textbf{白化性}(whitening)。
说一个零均值的随机向量$\bm{y}$是白的(或者说是白化的)
指它的各分量具有相同的单位方差且相互不相关，
换句话说，$\bm{y}$的协方差矩阵(包括相关矩阵)是单位矩阵：
\begin{equation}
E\{\bm{yy}^T\}=\bm{EDE}^T
\end{equation}
式中，$\bm{E}$是$E\{\bm{xx}^T\}$的特征向量的正交矩阵，
$\bm{D}$是相应的特征向量的对角矩阵，$\bm{D}=diag(d1,...,dn)$。
这样，白化过程可以利用下面的白化矩阵来实现：
\begin{equation}
\bm{V}=\bm{ED}^{-1/2}\bm{E}^T
\end{equation}
式中，矩阵$\bm{D}^{-1/2}$只需要通过简单的逐元素开方计算得到
$\bm{D}^{-1/2}=diag(d_1^{-1/2},...,d_n^{-1/2})$。
这样得到的白化矩阵记为$E\{\bm{xx}^T\}^(-1/2)$或$\bm{C}^(-1/2)$。
还有一种可以实现白化的方法是主成分分析，也可给出相关的白化矩阵。
白化过程将混合矩阵变换成一个新的矩阵~A，由式(***)和(***)可知：
\begin{equation}
\bm{z=VAs=\tilde{A}s}
\end{equation}
有人也许会希望白化过程能解决ICA问题，
因为白化或者不相关与独立性是相关联的，但事实却并非如此。
不相关的条件比独立要弱，且仅由此估计ICA模型是不够的。为了说明这个问题，
考虑对于z的一个正交变换：
\begin{equation}
\bm{y=Uz}
\end{equation}
由于U具有正交性，可知：
\begin{equation}
E\{\bm{yy}^T\}
=\tilde{\bm{A}}E\{\bm{ss}^T\}\tilde{\bm{A}}^T
=\tilde{\bm{A}}\tilde{\bm{A}}^T=\bm{I}
\end{equation}
这就意味着我们可以把对混合矩阵的搜索范围限制到正交矩阵的空间中。
我们可以无须估计原始矩阵的$\bm{A}$的全部$n^2$个参数(矩阵项)，
只要估计一个正交混合矩阵$\tilde{\bm{A}}$即可。
一个正交矩阵包含了n(n-1)/2个自由度。
举例来说二维正交变换仅仅由一个角度参量就能确定。在更高维的情况下，
正交矩阵包含的可变参数个数基本上只有任意矩阵参数个数的一半。

因此我们可以说白化过程解决了ICA问题的一半。
由于白化是一个非常简单的标准过程，比任何ICA算法都要简单，
故通过这样的方式降低问题的复杂程度应该是一个不错的想法。
剩下的一半参数必须通过其它手段去估计，其中一些方法在下面的章节中介绍。

在本文的很多章节中，我们都假定数据已经被白化处理过，
并把这样的数据定义为$\bm{z}$。即使在那些并没有明确白化需求的情况，
我们仍然建议进行白化处理，
因为该过程减少了自由参量的个数并明显提高算法的效率，
尤其在高维数据的情况下。
   
\subsection{时间滤波作为预处理}
因为对于时间序列的信号我们可以对它进行任意的线性滤波，
因为它并不改变ICA模型，当然混合矩阵也不会改变，其中有很多滤波方法。
    
\textbf{1) 低通滤波}：是平滑数据的一种方式，经常用来降噪。
基本ICA模型噪声的影响或多或少地被忽略了。
基本ICA模型对于没有很多噪声的数据效果较好，
因此降噪是有用的，有时甚至是必须的。

\textbf{2) 高通滤波和新息}：高通滤波是从数据中去掉缓慢变化的趋势，
其在某些情况下，会增加独立成分的独立性，因此在ICA中可能是有用的。
高通滤波一个更原则性的方法是按照新息(innovation)过程来考虑。
新息比原始过程常常更独立，而且可以认为新息通常比原始
过程非高斯性更强。高通滤波一个可能的问题是，可能会增加噪声。

\textbf{3) 最优滤波}：前面所讲的两种滤波都各自有优缺点。
最优滤波应该增加成分的独立性，同时降低噪声。为达到这一点，
在高通和低通滤波之间做某些折中可能会是最好的办法。
这导致带通滤波，它把最高和最低的频率成分滤掉，剩下中间一个合适的频带。
至于频带怎么选择无法给出一个一般的答案，它应该依赖于数据。
 
除了简单的低通/高通滤波，还可以有更复杂的方法。
例如，可以用(一维)小波变换(***)，也可以其它时频分解方法。
    
\subsection{用PCA进行预处理}
一个对多维数据降维的常用预处理方法是主成分分析(PCA)。
基本上，数据被先行投影到一个子空间：
\begin{equation}
\bm{\tilde{x}=E_n x}
\end{equation}
并保留了最多的信息(在最小二乘的意义上)。
这样做的好处有使混合矩阵成为方阵以及降噪和防止过学习等。
